---
title: "2019.11 Larval Toluene survival"
author: "Mikaela Nordborg"
date: "11/02/2020"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#For model fitting, evaluation & extraction of results
library(dplyr)
library(bayesnec) #devtools::install_github("open-AIMS/bayesnec")
require(tidyverse)
library(beepr)
inv.log10 <- function(x){10^x}
```


## Background
Analysis of data sets from A. millepora planula larvae experiments performed between 2016 and 2019 to test the effects of filtered seawater (FSW) solutions containing individual aromatic hydrocarbons in the presence and absence of ultraviolet radiation (+UV vs -UV). All analysis performed in (at least) four steps:
    - Model fitting, evaluation and interpretation of -UVR/PAR only treatment data
    - Model fitting, evaluation and interpretation of +UVR treatment data
    - Extraction of no effect concentration (NEC), 10 and 50% effect or lethal concentrations (EC/LCx) and associated 95% credible intervals.
    - Comparison of posterior distributions of extracted NEC and 50% threshold concentrations for each light treatment (+/-UV).

Compromised or invalid replicates identified prior to data import into R but removal is performed after import. Please see methods of main paper and *Table ___*, Supplementary materials for further details. Control treatment concentration-values set to 0.1 (~1/2 of the lowest treatment concentration used across all assays) to avoid potential issues with transformations after data import.Treatment concentrations log10 transformed and analysed on log-scale due to the spacing of treatment concentrations and range covered (equal to or larger than 3 orders of magnitude).


A majority of the data sets consist of binomial data and the following terms are used throughout:
    year = year and month experiment was performed
    endpoint = endpoint assessed
    factor = light treatment used
        PAR = -UVR/in the absence of UV light
        UV = +UVR/in the presence of UV light
    nom.x = nominal treatment or treatment concentration used (eg FSW or 0.01% DMSO controls)
    raw.x = time averaged, measured treatment concentration in μg L-1
    log.x = transformed, time-averaged, treatment concentrations (measured in μg L-1)
    suc = number of successes in sample (ie number of successfully metamorphosed larvae), generally a log10-transformation used
    tot = total number of organisms/larvae & recruits in sample at time of assessment
    prop = proportion of successes out of total tries/larvae in the sample


Data for some compounds available for several years and/or months. Each data set was analysed separately.


Analysis performed by Mikaela Nordborg and Dr. Rebecca Fisher.


## Packages used and installation of latest version of bayesnec

Analysis performed using package bayesnec and it's dependencies in R Version 4.0.3. The latest version of bayesnec and all dependencies were installed prior to start of analysis (28 January 2021).



## Analysis

### Import data, perform data preparation and check data types

Import data, wrangle and do quick initial checks
```{r}
data.Tol.19Nov.surv.raw<- read_csv("Data/2019.11_AM_tolu_surv.csv") %>% 
  data.frame() %>% 
  dplyr::mutate(raw.x=as.numeric(as.character(raw.x)),
                raw.x=ifelse(raw.x==0, 0.1, raw.x), # deal with 0 concentration values
                nom.x=as.factor(as.character(nom.x)),
                factor=as.factor(as.character(factor)),
                suc=as.integer(suc), # ensure integers
                log.x=log10(raw.x), # create log values (doesn't really matter if it's log or log10() unless there's a difference in the scaling of the x-data)
                tot=as.integer(tot))


save(data.Tol.19Nov.surv.raw, file = "2019.11_Tol_data_surv_raw.RData")

#Check that all columns have been assigned the correct data type & that adding 0.1 to raw.x controls worked
str(data.Tol.19Nov.surv.raw)
head(data.Tol.19Nov.surv.raw)
tail(data.Tol.19Nov.surv.raw)
```


Check for differences between 0.01% DMSO and FSW controls
```{r}
load("2019.11_Tol_data_surv_raw.RData")

#Remove treatment replicates from data set
data.Tol.19Nov.surv.controls <- data.Tol.19Nov.surv.raw %>% 
  dplyr::filter(nom.x!="Treatment")

#Plot to compare means and CIs
ggplot(data.Tol.19Nov.surv.controls, aes(x=nom.x, y=prop, fill=factor)) + 
    geom_boxplot()

#Filer in preparation for t-tests
Tol.19Nov.surv.controls.PAR.FSW <- data.Tol.19Nov.surv.controls %>% 
  dplyr::filter(factor=="PAR" & nom.x=="FSW")
Tol.19Nov.surv.controls.PAR.DMSO <- data.Tol.19Nov.surv.controls %>% 
  dplyr::filter(factor=="PAR" & nom.x!="FSW")

Tol.19Nov.surv.controls.UV.FSW <- data.Tol.19Nov.surv.controls %>% 
  dplyr::filter(factor=="UVR" & nom.x=="FSW")
Tol.19Nov.surv.controls.UV.DMSO <- data.Tol.19Nov.surv.controls %>% 
  dplyr::filter(factor=="UVR" & nom.x!="FSW")

#Perform t-test to check for differences between control groups
brms.fit <- brm(suc | trials(tot)  ~ nom.x*factor, data = data.Tol.19Nov.surv.controls, family = binomial())
new.dat <- data.frame(expand.grid(list(nom.x=c("FSW", "0.01% DMSO"),  "factor"=c("UVR", "PAR"),"tot"=1)))
post_preds <- posterior_epred(brms.fit, newdata=new.dat) %>% 
  data.frame

colnames(post_preds) <- paste(new.dat$nom.x, new.dat$factor)
pred_dat <-  post_preds %>% 
  pivot_longer(everything())

ggplot(pred_dat, aes(x=value)) + 
  geom_density(aes(group=name, colour=name, fill = name), alpha=0.3) +
  scale_x_continuous(labels = scales::percent, name ="Average survival") +
  scale_y_continuous(name ="Posterior probability density") +
  theme_classic() 
```

Calculate the mean survival using the posterior probability for each data set
```{r}
mean(post_preds[,1]) #FSW UVR
mean(post_preds[,2]) #0.01% DMSO UVR
mean(post_preds[,3]) #FSW PAR
mean(post_preds[,4]) #0.01% DMSO PAR
```


Calculate the median  survival using the posterior probability for each data set
```{r}
quantile(post_preds[,1], c(0.025, 0.5, 0.975)) #FSW UVR
quantile(post_preds[,2], c(0.025, 0.5, 0.975)) #0.01% DMSO UVR
quantile(post_preds[,3], c(0.025, 0.5, 0.975)) #FSW PAR
quantile(post_preds[,4], c(0.025, 0.5, 0.975)) #0.01% DMSO PAR
```


Filter remaining data according to light treatment + whether replicates should be included in statistical analysis and save to RData-files:
```{r}
load("2019.11_Tol_data_surv_raw.RData")

#Remove FSW control replicates
data.Tol.19Nov.surv <- data.Tol.19Nov.surv.raw %>% 
  dplyr::filter(nom.x!="FSW")

#Create -UVR data set and prep for use in model fitting
data.Tol.19Nov.surv.PAR.raw <- data.Tol.19Nov.surv %>% 
  dplyr::filter(factor=="PAR") 
data.Tol.19Nov.surv.PAR <- data.Tol.19Nov.surv.PAR.raw %>% 
  dplyr::filter(use_in_model=="Yes") 

#Create +UVR data set and prep for use in model fitting
data.Tol.19Nov.surv.UV.raw <- data.Tol.19Nov.surv %>% 
  dplyr::filter(factor=="UVR") 
data.Tol.19Nov.surv.UV <- data.Tol.19Nov.surv.UV.raw %>% 
  dplyr::filter(use_in_model=="Yes") 

#check that filtering worked
View(data.Tol.19Nov.surv.PAR)
View(data.Tol.19Nov.surv.UV)

#Save complete data sets and data sets prepared for model fitting
save(data.Tol.19Nov.surv.PAR.raw, data.Tol.19Nov.surv.UV.raw, data.Tol.19Nov.surv.PAR,data.Tol.19Nov.surv.UV, file = "2019.11_Tol_data_surv_filtered.RData")

load(file = "2019.11_Tol_data_surv_filtered.RData")
```

----------------------------------------------------------------
----------------------------------------------------------------


### -UV/PAR

#### Initial data exploration

Check distribution of response variable and range of treatment concentrations used
```{r}
load(file = "2019.11_Tol_data_surv_filtered.RData")

unique(data.Tol.19Nov.surv.PAR$raw.x)
par(mfrow=c(2,1))
hist(data.Tol.19Nov.surv.PAR$raw.x)
hist(data.Tol.19Nov.surv.PAR$suc/data.Tol.19Nov.surv.PAR$tot)
par(mfrow=c(1,1))
plot(data.Tol.19Nov.surv.PAR$log.x, data.Tol.19Nov.surv.PAR$prop) #use this to get an initial visual idea of priors to use (if setting priors manually)
```


##### Fit models

###### Binomial

Fit a model-averaged NEC-model (MANEC)
```{r, eval=FALSE}
load(file = "2019.11_Tol_data_surv_filtered.RData")
library(bayesnec)
library(beepr)
out.Tol.19Nov.surv.PAR.all <- bnec(data = data.Tol.19Nov.surv.PAR, 
                        x_var = "log.x", 
                        y_var = "suc", 
                        trials_var = "tot",
                        model = "all")
save(out.Tol.19Nov.surv.PAR.all, file = "2019.11_Tol_surv_PAR_modfit_all.RData")
beep("mario")
```


Check RHat values to discard bad candidate model fits
```{r}
load("2019.11_Tol_surv_PAR_modfit_all.RData")

rhat(out.Tol.19Nov.surv.PAR.all, rhat_cutoff = 1.03)
```

Drop candidate models that failed the RHat test (if required)
```{r}
out.Tol.19Nov.surv.PAR.all2 <- amend(out.Tol.19Nov.surv.PAR.all, drop = c("ecxll5", "ecxll4", "ecxhormebc5")) #add in bad candidate models in drop = c())
save(out.Tol.19Nov.surv.PAR.all, out.Tol.19Nov.surv.PAR.all2, file = "2019.11_Tol_surv_PAR_modfit_all.RData")
```


Check overdispersion estimates and candidate model weights
```{r}
load("2019.11_Tol_surv_PAR_modfit_all.RData")

out.Tol.19Nov.surv.PAR.all2$mod_stats
summary(out.Tol.19Nov.surv.PAR.all2)
```

*Any evidence of overdispersion?*
    - All candidate models are overdispersed.
    - ecxlin = highly overdispersed.
    

```{r}
plot(out.Tol.19Nov.surv.PAR.all2, add_ec10 = TRUE, add_nec = FALSE, lxform = inv.log10) #if modelled on log(raw.x) use: lxform = exp
```    
    


###### Betabinomial

Re-fit MANEC using a distribution appropriate for overdispersed binomial data
```{r}
load(file = "2019.11_Tol_data_surv_filtered.RData")
library(bayesnec)
library(beepr)
out.Tol.19Nov.surv.PAR.all.od <- bnec(data = data.Tol.19Nov.surv.PAR, 
                        x_var = "log.x", 
                        y_var = "suc", 
                        trials_var = "tot",
                        model = "all",
                        family = beta_binomial2)

save(out.Tol.19Nov.surv.PAR.all.od, file = "2019.11_Tol_surv_PAR_modfit_all_OD.RData")
beep("mario")
```


Check RHat values to discard bad candidate model fits
```{r}
load("2019.11_Tol_surv_PAR_modfit_all_OD.RData")
rhat(out.Tol.19Nov.surv.PAR.all.od, rhat_cutoff = 1.03)
```

Drop candidate models that failed the RHat test (if required)
```{r}
out.Tol.19Nov.surv.PAR.all.od2 <- amend(out.Tol.19Nov.surv.PAR.all.od, drop = c("ecxll5")) #add in bad candidate models in drop = c())
save(out.Tol.19Nov.surv.PAR.all.od, out.Tol.19Nov.surv.PAR.all.od2, file = "2019.11_Tol_surv_PAR_modfit_all_OD.RData")
```


Check chain mixing and model summaries for remaining candidate models
```{r}
load("2019.11_Tol_surv_PAR_modfit_all_OD.RData")

check_chains(out.Tol.19Nov.surv.PAR.all.od2, filename = "2019.11_Tol_surv_PAR_chains_modfit_all_OD") #change this if any candidate models were discarded based on Rhat: 
out.Tol.19Nov.surv.PAR.all.od2$mod_stats
summary(out.Tol.19Nov.surv.PAR.all.od2)
```

*Any evidence of non-convergence, poor chain mixing or autocorrelation?*
    - model =       include/unclear/exclude     (reason for potential exclusion)
    
    - neclinhorme =           include           (minor-some evidence of poor chain mixing)
    - ecx4param =             include           (minor evidence of poor chain mixing)
    - ecxhormebc5 =           exclude           (some evidence of poor chain mixing)


```{r}
plot(out.Tol.19Nov.surv.PAR.all.od2, add_ec10 = TRUE, add_nec = FALSE, lxform = inv.log10) #if modelled on log(raw.x) use: lxform = exp
```

  
Check if model median, credible intervals and NEC estimates are reasonable for candidate models compared to the raw data
```{r}
load("2019.11_Tol_surv_PAR_modfit_all_OD.RData")
pdf("2019.11_Tol_surv_PAR_modfitplots_all_OD.pdf")
plot(out.Tol.19Nov.surv.PAR.all.od2, all_models = TRUE, add_ec10 = FALSE, add_nec = TRUE, lxform = inv.log10) #if modelled on log(raw.x) use: lxform = exp
dev.off()
```


Drop inappropriate models and models with non-convergence or very poor chain mixing (if required)
```{r}
out.Tol.19Nov.surv.PAR.mod.od <- amend(out.Tol.19Nov.surv.PAR.all.od2, drop = c("ecxhormebc5"))
```


Compare the MANEC containing all OD candidate models to the amended MANEC
```{r}
plot(out.Tol.19Nov.surv.PAR.all.od2, add_ec10 = TRUE, add_nec = FALSE, lxform = inv.log10) #if modelled on log(raw.x) use: lxform = exp
plot(out.Tol.19Nov.surv.PAR.mod.od, add_ec10 = TRUE, add_nec = FALSE, lxform = inv.log10) #if modelled on log(raw.x) use: lxform = exp
```


###### Compare binomial and betabinomial MANECs and select which one to use

Compare the amended OD MANEC to the MANEC fitted using the binomial distribution
```{r}
plot(out.Tol.19Nov.surv.PAR.all2, add_ec10 = TRUE, add_nec = FALSE, lxform = inv.log10) #if modelled on log(raw.x) use: lxform = exp
plot(out.Tol.19Nov.surv.PAR.mod.od, add_ec10 = TRUE, add_nec = FALSE, lxform = inv.log10) #if modelled on log(raw.x) use: lxform = exp
```


*Did using the betabinomial distribution improve MANEC model fit compared to the MANEC fit using the binomial distribution?*
    -> Yes.


Rename model output for selected model (binomial or betabinomial)
```{r}
out.Tol.19Nov.surv.PAR <- out.Tol.19Nov.surv.PAR.mod.od
```


Extract the NEC-model subset for use in extraction of NEC and comparisons of posterior distributions
```{r}
out.Tol.19Nov.surv.PAR.NEC <- pull_out(out.Tol.19Nov.surv.PAR, model = c("nec"))
```


```{r}
plot(out.Tol.19Nov.surv.PAR.NEC, add_nec = TRUE, lxform = inv.log10) #if modelled on log(raw.x) use: lxform = exp
```


Save the output for the selected models
```{r}
save(out.Tol.19Nov.surv.PAR, out.Tol.19Nov.surv.PAR.NEC, file = "2019.11_Tol_surv_PAR_modfits_final.RData")
load("2019.11_Tol_surv_PAR_modfits_final.RData")
```



#### Extract results

Extract NEC, LC10 and LC50 (with 95% credible intervals) from posterior and backtransform if required
```{r}
load("2019.11_Tol_surv_PAR_modfits_final.RData")
NEC.Tol.19Nov.surv.PAR <- out.Tol.19Nov.surv.PAR.NEC$w_nec
NEC.Tol.19Nov.surv.PAR <- 10^NEC.Tol.19Nov.surv.PAR #if using log10(raw.x)
#NEC.Tol.19Nov.surv.PAR <- exp(NEC.Tol.19Nov.surv.PAR) #if using log(raw.x))
NEC.Tol.19Nov.surv.PAR
```

```{r}
load("2019.11_Tol_surv_PAR_modfits_final.RData")
LC10.Tol.19Nov.surv.PAR <- ecx(out.Tol.19Nov.surv.PAR, ecx_val = 10, type = "absolute")
LC10.Tol.19Nov.surv.PAR <- 10^LC10.Tol.19Nov.surv.PAR #if using log10(raw.x)
#LC10.Tol.19Nov.surv.PAR <- exp(LC10.Tol.19Nov.surv.PAR) #if using log(raw.x))
LC10.Tol.19Nov.surv.PAR
```

```{r}
load("2019.11_Tol_surv_PAR_modfits_final.RData")
LC50.Tol.19Nov.surv.PAR <- ecx(out.Tol.19Nov.surv.PAR, ecx_val = 50, type = "absolute")
LC50.Tol.19Nov.surv.PAR <- 10^LC50.Tol.19Nov.surv.PAR #if using log10(raw.x)
#LC50.Tol.19Nov.surv.PAR <- exp(LC50.Tol.19Nov.surv.PAR) #if using log(raw.x))
LC50.Tol.19Nov.surv.PAR
```
    
----------------------------------------------------------------
----------------------------------------------------------------


### +UV/UV

#### Initial data exploration

Check distribution of response variable and range of treatment concentrations used
```{r}
load(file = "2019.11_Tol_data_surv_filtered.RData")

unique(data.Tol.19Nov.surv.UV$raw.x)
par(mfrow=c(2,1))
hist(data.Tol.19Nov.surv.UV$raw.x)
hist(data.Tol.19Nov.surv.UV$suc/data.Tol.19Nov.surv.UV$tot)
par(mfrow=c(1,1))
plot(data.Tol.19Nov.surv.UV$log.x, data.Tol.19Nov.surv.UV$prop) #use this to get an initial visual idea of priors to use (if setting priors manually)
```


##### Fit models

###### Binomial

Fit a model-averaged NEC-model (MANEC)
```{r, eval=FALSE}
load(file = "2019.11_Tol_data_surv_filtered.RData")

library(bayesnec)
library(beepr)
out.Tol.19Nov.surv.UV.all <- bnec(data = data.Tol.19Nov.surv.UV, 
                        x_var = "log.x", 
                        y_var = "suc", 
                        trials_var = "tot",
                        model = "all")

save(out.Tol.19Nov.surv.UV.all, file = "2019.11_Tol_surv_UV_modfit_all.RData")
beep("mario")
```


Check RHat values to discard bad candidate model fits
```{r}
load("2019.11_Tol_surv_UV_modfit_all.RData")

rhat(out.Tol.19Nov.surv.UV.all, rhat_cutoff = 1.03)
```

Drop candidate models that failed the RHat test (if required)
```{r}
load("2019.11_Tol_surv_UV_modfit_all.RData")

out.Tol.19Nov.surv.UV.all2 <- amend(out.Tol.19Nov.surv.UV.all, drop = c("ecxll5")) #add in bad candidate models in drop = c())
save(out.Tol.19Nov.surv.UV.all, out.Tol.19Nov.surv.UV.all2, file = "2019.11_Tol_surv_UV_modfit_all.RData")
```


Check overdispersion estimates and candidate model weights
```{r}
load("2019.11_Tol_surv_UV_modfit_all.RData")

out.Tol.19Nov.surv.UV.all2$mod_stats
summary(out.Tol.19Nov.surv.UV.all2)
```

*Any evidence of overdispersion?*
    - All candidate models overdispersed.
    - ecxlin = very overdispersed.


```{r}
plot(out.Tol.19Nov.surv.UV.all2, add_ec10 = TRUE, add_nec = FALSE, lxform = inv.log10) #if modelled on log(raw.x) use: lxform = exp
```



###### Betabinomial

Re-fit MANEC using a distribution appropriate for overdispersed binomial data
```{r}
load(file = "2019.11_Tol_data_surv_filtered.RData")
library(bayesnec)
library(beepr)
out.Tol.19Nov.surv.UV.all.od <- bnec(data = data.Tol.19Nov.surv.UV, 
                        x_var = "log.x", 
                        y_var = "suc", 
                        trials_var = "tot",
                        model = "all",
                        family = beta_binomial2)

save(out.Tol.19Nov.surv.UV.all.od, file = "2019.11_Tol_surv_UV_modfit_all_OD.RData")
beep("mario")
```


Check RHat values to discard bad candidate model fits
```{r}
load("2019.11_Tol_surv_UV_modfit_all_OD.RData")

rhat(out.Tol.19Nov.surv.UV.all.od, rhat_cutoff = 1.03)
```

Drop candidate models that failed the RHat test (if required)
```{r}
load("2019.11_Tol_surv_UV_modfit_all_OD.RData")

out.Tol.19Nov.surv.UV.all.od2 <- amend(out.Tol.19Nov.surv.UV.all.od, drop = c("ecxll5")) #add in bad candidate models in drop = c())
save(out.Tol.19Nov.surv.UV.all.od, out.Tol.19Nov.surv.UV.all.od2, file = "2019.11_Tol_surv_UV_modfit_all_OD.RData")
```


Check chain mixing for remaining candidate models
```{r}
load("2019.11_Tol_surv_UV_modfit_all_OD.RData")

check_chains(out.Tol.19Nov.surv.UV.all.od2, filename = "2019.11_Tol_surv_UV_chains_modfit_all_OD") #change this if any candidate models were discarded based on Rhat: out.Tol.19Nov.surv.UV.all.od2
out.Tol.19Nov.surv.UV.all.od2$mod_stats
summary(out.Tol.19Nov.surv.UV.all.od2)
```

*Any evidence of non-convergence, poor chain mixing or autocorrelation?*
    - No.


```{r}
plot(out.Tol.19Nov.surv.UV.all.od2, add_ec10 = TRUE, add_nec = FALSE, lxform = inv.log10) #if modelled on log(raw.x) use: lxform = exp
```

    
Check if model median, credible intervals and NEC estimates are reasonable for candidate models compared to the raw data
```{r}
load("2019.11_Tol_surv_UV_modfit_all_OD.RData")
pdf("2019.11_Tol_surv_UV_modfitplots_all_OD.pdf")
plot(out.Tol.19Nov.surv.UV.all.od2, all_models = TRUE, add_ec10 = FALSE, add_nec = TRUE, lxform = inv.log10) #if modelled on log(raw.x) use: lxform = exp
dev.off()
```



###### Compare binomial and betabinomial MANECs and select model to use

Compare to MANEC fitted using the binomial distribution
```{r}
plot(out.Tol.19Nov.surv.UV.all2, add_ec10 = TRUE, add_nec = FALSE, lxform = inv.log10)
plot(out.Tol.19Nov.surv.UV.all.od2, add_ec10 = TRUE, add_nec = FALSE, lxform = inv.log10)
```


*Did using the betabinomial distribution improve MANEC model fit compared to the MANEC fit using the binomial distribution?*
    - It slightly widened the credible intervals.


Rename model output for selected model (binomial or betabinomial)
```{r}
out.Tol.19Nov.surv.UV <- out.Tol.19Nov.surv.UV.all.od2
```


Extract the NEC-model subset for use in extraction of NEC and comparisons of posterior distributions
```{r}
out.Tol.19Nov.surv.UV.NEC <- pull_out(out.Tol.19Nov.surv.UV, model = c("nec"))
```


```{r}
plot(out.Tol.19Nov.surv.UV.NEC, add_nec = TRUE, lxform = inv.log10) #if modelled on log(raw.x) use: lxform = exp
```


Save the output for the selected models
```{r}
save(out.Tol.19Nov.surv.UV, out.Tol.19Nov.surv.UV.NEC, file = "2019.11_Tol_surv_UV_modfits_final.RData")
load("2019.11_Tol_surv_UV_modfits_final.RData")
```



#### Extract results

Extract NEC, LC10 and LC50 (with 95% credible intervals) from posterior and backtransform if required
```{r}
load("2019.11_Tol_surv_UV_modfits_final.RData")
NEC.Tol.19Nov.surv.UV <- out.Tol.19Nov.surv.UV.NEC$w_nec
NEC.Tol.19Nov.surv.UV <- 10^NEC.Tol.19Nov.surv.UV #if using log10(raw.x)
#NEC.Tol.19Nov.surv.UV <- exp(NEC.Tol.19Nov.surv.UV) #if using log(raw.x)
NEC.Tol.19Nov.surv.UV
```

```{r}
load("2019.11_Tol_surv_UV_modfits_final.RData")
LC10.Tol.19Nov.surv.UV <- ecx(out.Tol.19Nov.surv.UV, ecx_val = 10, type = "absolute")
LC10.Tol.19Nov.surv.UV <- 10^LC10.Tol.19Nov.surv.UV #if using log10(raw.x)
#LC10.Tol.19Nov.surv.UV <- exp(LC10.Tol.19Nov.surv.UV) #if using log(raw.x)
LC10.Tol.19Nov.surv.UV
```

```{r}
load("2019.11_Tol_surv_UV_modfits_final.RData")
LC50.Tol.19Nov.surv.UV <- ecx(out.Tol.19Nov.surv.UV, ecx_val = 50, type = "absolute")
LC50.Tol.19Nov.surv.UV <- 10^LC50.Tol.19Nov.surv.UV #if using log10(raw.x)
#LC50.Tol.19Nov.surv.UV <- exp(LC50.Tol.19Nov.surv.UV) #if using log(raw.x)
LC50.Tol.19Nov.surv.UV
```

----------------------------------------------------------------
----------------------------------------------------------------


### Compare light treatments and pLot results

```{r}
#For plotting results & model/threshold value comparisons
library(ggplot2)
library(scales)
library(tidybayes)

#For creating layouts & exports
library(ggpubr) #devtools::install_github("kassambara/ggpubr")
```


Extract complete posteriors for the fitted values using compare_posterior-function
```{r}
load("2019.11_Tol_surv_PAR_modfits_final.RData")
load("2019.11_Tol_surv_UV_modfits_final.RData")

pred.Tol.19Nov.surv <- compare_posterior(x=list("PAR" = out.Tol.19Nov.surv.PAR, "UVR" = out.Tol.19Nov.surv.UV), comparison = "fitted", precision = 50)

pred.Tol.19Nov.surv.PAR <- pred.Tol.19Nov.surv$posterior_data %>% 
  dplyr::filter(model=="PAR")

pred.Tol.19Nov.surv.UV <- pred.Tol.19Nov.surv$posterior_data %>% 
  dplyr::filter(model=="UVR")



pred.Tol.19Nov.surv.NEC <- compare_posterior(list("PAR" = out.Tol.19Nov.surv.PAR.NEC, "UVR" = out.Tol.19Nov.surv.UV.NEC), comparison = "fitted", precision = 50)

pred.Tol.19Nov.surv.PAR.NEC <- pred.Tol.19Nov.surv.NEC$posterior_data %>% 
  dplyr::filter(model=="PAR")
pred.Tol.19Nov.surv.UV.NEC <- pred.Tol.19Nov.surv.NEC$posterior_data %>% 
 dplyr::filter(model=="UVR")


save(pred.Tol.19Nov.surv, pred.Tol.19Nov.surv.PAR, pred.Tol.19Nov.surv.UV, pred.Tol.19Nov.surv.PAR.NEC, pred.Tol.19Nov.surv.UV.NEC, file = "2019.11_Tol_surv_predvals.RData") # pred.Tol.19Nov.surv.NEC, pred.Tol.19Nov.surv.PAR.NEC, pred.Tol.19Nov.surv.UV.NEC <- add these back in once UV-section is working

load("2019.11_Tol_surv_predvals.RData")
str(pred.Tol.19Nov.surv.PAR)
str(pred.Tol.19Nov.surv.UV)
```


#### Plot MANEC model fits alongside raw data
##### Complete subset-MANEC plot

```{r}
load("2019.11_Tol_data_surv_filtered.RData")
load("2019.11_Tol_surv_predvals.RData")

p.all= ggplot()
p.all= p.all+ scale_color_manual(values = c("UVR" = "steelblue", "PAR" = "seagreen")) + theme_light()


p.all= p.all+  geom_ribbon(aes(x=10^pred.Tol.19Nov.surv.PAR$x, ymin=pred.Tol.19Nov.surv.PAR$Q2.5, ymax=pred.Tol.19Nov.surv.PAR$Q97.5, fill="seagreen"),  alpha=0.3) #Seagreen HEX code: #2e8b57
#p.all= p.all+  scale_fill_manual(values=c("seagreen", "steelblue"))
p.all= p.all+  geom_ribbon(aes(x=10^pred.Tol.19Nov.surv.UV$x, ymin=pred.Tol.19Nov.surv.UV$Q2.5, ymax=pred.Tol.19Nov.surv.UV$Q97.5, fill="steelblue",  alpha=0.3))
#p.all= p.all+  scale_fill_manual(values="steelblue")


p.all= p.all+ geom_line(aes(x=10^pred.Tol.19Nov.surv.PAR$x, y=pred.Tol.19Nov.surv.PAR$Estimate), color = 'grey30', size=0.5)
p.all= p.all+ geom_line(aes(x=10^pred.Tol.19Nov.surv.UV$x, y=pred.Tol.19Nov.surv.UV$Estimate), color = 'grey30', size=0.5)


p.all= p.all+ geom_point(data = data.Tol.19Nov.surv.PAR, aes(x = raw.x, y = prop, colour=factor(factor), shape = factor(factor), alpha = 0.3), size = 2.5, position=position_jitter(width = .025, height=0.02))
p.all= p.all+ geom_point(data = data.Tol.19Nov.surv.UV, aes(x = raw.x, y = prop, colour=factor(factor), shape = factor(factor), alpha = 0.3), size = 2, position=position_jitter(width = .025, height=0.02))


p.all = p.all+ labs(x=expression(), #Concentration~(μg~"L"^{-1})
              y=expression(Survival~("%")),
              subtitle="a) Toluene")
p.all= p.all+ scale_y_continuous( limits = c(-0.03, 1.05), breaks = c(0, 0.25, 0.5, 0.75, 1.0), labels = c(0, 25, 50, 75, 100)) 
p.all= p.all+ theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_blank(), panel.border = element_blank(), axis.line = element_line(colour = "grey80"))
p.all= p.all+ scale_fill_manual(values = c("seagreen", "steelblue"))
p.all= p.all+ theme(legend.position="none")
# p.all = p.all  + theme(legend.position = c(0.9, 0.9))
p.all= p.all+ scale_x_continuous(limits = c(0.09, 30000), trans="log10", breaks = c(0.1, 1, 10, 100, 1000, 10000), labels = c(0, 1, 10, 100, 1000, 10000))
#p.all= p.all+ facet_wrap(~factor, nrow = 1)


#Rename & show plot
plot.Tol.19Nov.surv.all <- p.all
plot.Tol.19Nov.surv.all
```


#### NEC subset-MANEC plot

```{r}
load("2019.11_Tol_data_surv_filtered.RData")
load("2019.11_Tol_surv_predvals.RData")

p.NEC= ggplot()
p.NEC= p.NEC+ scale_color_manual(values = c("UVR" = "steelblue", "PAR" = "seagreen")) + theme_light()


p.NEC= p.NEC+  geom_ribbon(aes(x=10^pred.Tol.19Nov.surv.PAR.NEC$x, ymin=pred.Tol.19Nov.surv.PAR.NEC$Q2.5, ymax=pred.Tol.19Nov.surv.PAR.NEC$Q97.5, fill="seagreen"),  alpha=0.3) #Seagreen HEX code: #2e8b57
#p.NEC= p.NEC+  scale_fill_manual(values=c("seagreen", "steelblue"))
p.NEC= p.NEC+  geom_ribbon(aes(x=10^pred.Tol.19Nov.surv.UV.NEC$x, ymin=pred.Tol.19Nov.surv.UV.NEC$Q2.5, ymax=pred.Tol.19Nov.surv.UV.NEC$Q97.5,fill="steelblue",  alpha=0.3))
#p.NEC= p.NEC+  scale_fill_manual(values="steelblue")


p.NEC= p.NEC+ geom_line(aes(x=10^pred.Tol.19Nov.surv.PAR.NEC$x, y=pred.Tol.19Nov.surv.PAR.NEC$Estimate), color = 'grey30', size=0.5)
p.NEC= p.NEC+ geom_line(aes(x=10^pred.Tol.19Nov.surv.UV.NEC$x, y=pred.Tol.19Nov.surv.UV.NEC$Estimate), color = 'grey30', size=0.5)


p.NEC= p.NEC+ geom_point(data = data.Tol.19Nov.surv.PAR, aes(x = raw.x, y = prop, colour=factor(factor), shape = factor(factor), alpha = 0.3), size = 2.5, position=position_jitter(width = .025, height=0.02))
p.NEC= p.NEC+ geom_point(data = data.Tol.19Nov.surv.UV, aes(x = raw.x, y = prop, colour=factor(factor), shape = factor(factor), alpha = 0.3), size = 2, position=position_jitter(width = .025, height=0.02))


p.NEC = p.NEC+ labs(x=expression(Concentration~(μg~"L"^{-1})),
              y=expression(Survival~("%")),
              subtitle="a) Toluene")
p.NEC= p.NEC+ scale_y_continuous( limits = c(-0.03, 1.05), breaks = c(0, 0.25, 0.5, 0.75, 1.0), labels = c(0, 25, 50, 75, 100)) 
p.NEC= p.NEC+ theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_blank(), panel.border = element_blank(), axis.line = element_line(colour = "grey80"))
p.NEC= p.NEC+ scale_fill_manual(values = c("seagreen", "steelblue"))
p.NEC= p.NEC+ theme(legend.position="none")
# p.NEC = p.NEC  + theme(legend.position = c(0.9, 0.9))
p.NEC= p.NEC+ scale_x_continuous(limits = c(0.09, 30000), trans="log10", breaks = c(0.1, 1, 10, 100, 1000, 10000), labels = c(0, 1, 10, 100, 1000, 10000))
#p.NEC= p.NEC+ facet_wrap(~factor, nrow = 1)


#Rename & show plot
plot.Tol.19Nov.surv.NEC <- p.NEC
plot.Tol.19Nov.surv.NEC
```

----------------------------------------------------------------
----------------------------------------------------------------


### Compare +/-UV posteriors

#### Full model comparisons

Extract the highest probability that the fitted values/posteriors for the two light treatments are different (at any tested x-value):
```{r}
load("2019.11_Tol_surv_predvals.RData")

diff.prob.Tol.19Nov.surv <- max(pred.Tol.19Nov.surv$prob_diff$prob)
diff.prob.Tol.19Nov.surv
```


Plot the probability of a difference between the UV and PAR light treatments across the treatment concentrations tested
```{r}
load("2019.11_Tol_surv_predvals.RData")

pred.Tol.19Nov.surv$prob_diff$inv.x <- 10^pred.Tol.19Nov.surv$prob_diff$x

p.comp.prob= ggplot(pred.Tol.19Nov.surv$prob_diff) +
                geom_line(aes(x=inv.x, prob, color="grey"), size=0.8)

p.comp.prob= p.comp.prob + scale_color_manual(values = c("grey")) +
                theme_light() +
                theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_blank(), panel.border = element_blank(), axis.line = element_line(colour = "grey80")) +
                theme(legend.position="none") 
    
p.comp.prob= p.comp.prob + scale_y_continuous(breaks = c(0, 0.25, 0.5, 0.75, 1.0), labels = c(0, 25, 50, 75, 100)) +
                scale_x_continuous(limits = c(0.09, 30000), trans="log10", breaks = c(0.1, 1, 10, 100, 1000, 10000), labels = c(0, 1, 10, 100, 1000, 10000)) +
                labs(x=expression(Treatment~concentration~(μg~"L"^{-1})),
                      y=expression(Probability~that~UVR~affected~toxicity~("%")),
                      subtitle="a)")

plot.Tol.19Nov.surv.diff.prob <- p.comp.prob
plot.Tol.19Nov.surv.diff.prob
```

    If solid line (probability) is higher than 95%/0.95 = UVR significantly increased toxicity at that treatment concentration


Plot the posterior difference estimate for the UV and PAR light treatments across the treatment concentrations tested
```{r}
load("2019.11_Tol_surv_predvals.RData")

pred.Tol.19Nov.surv$diff_data$inv.x <- 10^pred.Tol.19Nov.surv$diff_data$x

p.comp.diff = ggplot(pred.Tol.19Nov.surv$diff_data) +
  geom_ribbon(aes(x=inv.x, ymin=diff.Q2.5, ymax=diff.Q97.5, fill = 'grey'), alpha=0.4) +
  geom_line(aes(x=inv.x, diff.Estimate, color="grey"), size=0.8) +
  geom_hline(yintercept = 0, color = "steelblue3", lty = 2, size=0.75)


p.comp.diff= p.comp.diff + scale_fill_manual( values = c("grey", "steelblue3")) +
                scale_color_manual(values = c("grey", "steelblue3")) 
  
p.comp.diff= p.comp.diff + theme_light() + 
                theme(legend.position="none") +
                theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_blank(), panel.border = element_blank(), axis.line = element_line(colour = "grey80"))

p.comp.diff= p.comp.diff + scale_y_continuous(name = "Posterior differences estimate") 
p.comp.diff= p.comp.diff + scale_x_continuous(limits = c(0.09, 30000), trans="log10", breaks = c(0.1, 1, 10, 100, 1000, 10000), labels = c(0, 1, 10, 100, 1000, 10000)) +
              labs(x=expression(Treatment~concentration~(μg~"L"^{-1})),
                  y=expression(Posterior~difference~estimate),
                  subtitle="a)")

plot.Tol.19Nov.surv.diff.est <- p.comp.diff
plot.Tol.19Nov.surv.diff.est
```

    If credible intervals (shaded grey area) includes 0 (dotted blue line) there is no significant difference between the two models at that treatment concentration.




#### LC50

Perform comparison of posterior distributions for metamorphosis LC50
```{r}
load("2019.11_Tol_surv_PAR_modfits_final.RData")
load("2019.11_Tol_surv_UV_modfits_final.RData")

comp.Tol.19Nov.surv.LC50 <- compare_posterior(x=list("PAR" = out.Tol.19Nov.surv.PAR, "UVR" = out.Tol.19Nov.surv.UV), comparison = "ecx", ecx_val = 50)
save(comp.Tol.19Nov.surv.LC50, file = "2019.11_Tol_surv_posterior_comp_LC50.RData")
comp.Tol.19Nov.surv.LC50$prob_diff
```

    Table shows the % likelihood that the point estimate calculated (NEC, EC/LC10 or EC/LC50) for model A (in top row) is smaller than the point estimate calculated for model B, C, etc (in left hand column). 

*Is LC50 +UVR lower than the LC50 -UVR?*
    - No, but still with a likelihood of 71.48%


Create a custom results plot of the LC50 comparison
```{r}
load("2019.11_Tol_surv_posterior_comp_LC50.RData")

p.comp.LC50 = ggplot(comp.Tol.19Nov.surv.LC50$posterior_data, aes(x=value))+geom_density(aes(group=model, color=model, fill=model), alpha=0.4) 
p.comp.LC50 = p.comp.LC50 + stat_pointinterval(aes(y = 0.00, x = value, group=model),.width = c(.66, .95), size=0.5)+
  theme_light()

p.comp.LC50 = p.comp.LC50 + scale_fill_manual( values = c("seagreen", "steelblue")) +
  scale_color_manual(values = c("grey","grey", "steelblue1","steelblue", "grey","grey", "grey","grey"))+theme(legend.position="none")
p.comp.LC50 = p.comp.LC50 + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_blank(), panel.border = element_blank(), axis.line = element_line(colour = "grey80"))

p.comp.LC50 = p.comp.LC50 + scale_y_continuous(limits = c(-0.5, 15), name ="Posterior probability density") 
p.comp.LC50 = p.comp.LC50 + scale_x_continuous(limits = c(-1.02, 4.7), breaks = c(-1, 0, 1, 2, 3, 4), labels = c(0, 1, 10, 100, 1000, 10000)) #update breaks+labels to match the scale given by the automatic compare_posterior output
p.comp.LC50 = p.comp.LC50 + labs(x=expression(), #LC50~(μg~"L"^{-1})
               subtitle="b)")

p.comp.LC50= p.comp.LC50+ annotate("text", label = expression(Probability~of~LC[50]~difference), x = 0.55, y = 12, size = 2.8, colour = "grey20") #0.8 of the max y-axis limit
p.comp.LC50= p.comp.LC50+ annotate("text", label = "UVR < PAR = 71.48%", x = 0.55, y = 10.87, size = 2.4, colour = "grey20") #0.906 of the first annotation


#Rename & show plot
comp.plot.Tol.19Nov.surv.LC50 <- p.comp.LC50
comp.plot.Tol.19Nov.surv.LC50
```


Create a custom plot of the LC50 comparisons differences posterior density
```{r}
load("2019.11_Tol_surv_posterior_comp_LC50.RData")

p.comp.LC50.diff = ggplot(comp.Tol.19Nov.surv.LC50$diff_data, aes(x=diff)) +
  geom_density(aes(x=diff, fill = 'grey'), alpha=0.4) + 
  geom_vline(xintercept = 0, color = "steelblue3", lty = 2, size=0.75) + 
  theme_light()

p.comp.LC50.diff = p.comp.LC50.diff + scale_fill_manual( values = c("grey", "steelblue3")) +
  scale_color_manual(values = c("grey","steelblue3")) + 
  theme(legend.position="none")
p.comp.LC50.diff = p.comp.LC50.diff + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_blank(), panel.border = element_blank(), axis.line = element_line(colour = "grey80"))

p.comp.LC50.diff = p.comp.LC50.diff + scale_y_continuous(name = "Differences posterior density") 
p.comp.LC50.diff = p.comp.LC50.diff + scale_x_continuous(name = "Standardized effect size") 


#Rename & show plot
comp.plot.Tol.19Nov.surv.LC50.diff <- p.comp.LC50.diff
comp.plot.Tol.19Nov.surv.LC50.diff
```


##### If no difference was detected -> calculate LC50 geometric mean and check againstthe original LC50s

```{r}
LC50.Tol.19Nov.surv.geomean <- average_endpoints(x=list("Tol_PAR" = out.Tol.19Nov.surv.PAR, "Tol_UV" = out.Tol.19Nov.surv.UV), endpoint = "ecx", ecx_val = 50, xform = inv.log10)
LC50.Tol.19Nov.surv.geomean
LC50.Tol.19Nov.surv.PAR
LC50.Tol.19Nov.surv.UV
```



#### NEC

Perform comparison of posterior distributions for metamorphosis NEC
```{r}
load("2019.11_Tol_surv_PAR_modfits_final.RData")
load("2019.11_Tol_surv_UV_modfits_final.RData")

comp.Tol.19Nov.surv.NEC <- compare_posterior(x=list("PAR" = out.Tol.19Nov.surv.PAR, "UVR" = out.Tol.19Nov.surv.UV), comparison = "nec")
save(comp.Tol.19Nov.surv.NEC, file = "2019.11_Tol_surv_posterior_comp_NEC.RData")
comp.Tol.19Nov.surv.NEC$prob_diff
```

    Table shows the % likelihood that the point estimate calculated (NEC, EC/LC10 or EC/LC50) for model A (in top row) is smaller than the point estimate calculated for model B, C, etc (in left hand column). 

*Is the NEC +UVR lower than the NEC -UVR?*
    - No, with a likelihood of 1.17%.


Create a custom results plot of the NEC comparison
```{r}
load("2019.11_Tol_surv_posterior_comp_NEC.RData")

p.comp.NEC = ggplot(comp.Tol.19Nov.surv.NEC$posterior_data, aes(x=value))+geom_density(aes(group=model, color=model, fill=model), alpha=0.4) 
p.comp.NEC = p.comp.NEC + stat_pointinterval(aes(y=0.00, x=value, group=model),.width=c(.66, .95), size=0.5) +
  theme_light()

p.comp.NEC = p.comp.NEC + scale_fill_manual(values=c("seagreen", "steelblue"))+
  scale_color_manual(values = c("grey","grey", "steelblue1","steelblue", "grey","grey", "grey","grey")) + theme(legend.position="none")
p.comp.NEC = p.comp.NEC + theme(panel.grid.major = element_blank(), panel.grid.minor=element_blank(), panel.background=element_blank(), panel.border=element_blank(), axis.line=element_line(colour="grey80"))

p.comp.NEC = p.comp.NEC + scale_y_continuous(limits = c(-0.5, 5), name="Posterior probability density") 
p.comp.NEC = p.comp.NEC + scale_x_continuous(limits = c(-1.02, 4.5), breaks = c(-1, 0, 1, 2, 3, 4), labels = c(0, 1, 10, 100, 1000, 10000)) #update breaks+labels to match the scale given by the automatic compare_posterior output
p.comp.NEC = p.comp.NEC + labs(x=expression(Threshold~concentration~(μg~"L"^{-1})),
               subtitle="d)")

p.comp.NEC= p.comp.NEC+ annotate("text", label = expression(Probability~of~NEC~difference), x = 0.55, y = 4, size = 2.8, colour = "grey20") #0.8 of the max y-axis limit
p.comp.NEC= p.comp.NEC+ annotate("text", label = "UVR < PAR = 1.17%", x = 0.55, y = 3.62, size = 2.4, colour = "grey20") #0.906 of the first annotation


#Rename and show plot
comp.plot.Tol.19Nov.surv.NEC <- p.comp.NEC
comp.plot.Tol.19Nov.surv.NEC
```


Create a custom plot of the NEC comparisons differences posterior density
```{r}
load("2019.11_Tol_surv_posterior_comp_NEC.RData")

p.comp.NEC.diff = ggplot(comp.Tol.19Nov.surv.NEC$diff_data, aes(x=diff)) + 
  geom_density(aes(x=diff, fill = 'grey'), alpha=0.4) + 
  stat_pointinterval(aes(y = 0.00, x = comp.Tol.19Nov.surv.NEC$df4.s$diff),.width = c(.66, .95)) +
   geom_vline(xintercept = 0, color = "steelblue3", lty = 2, size=0.75) + theme_light()

p.comp.NEC.diff = p.comp.NEC.diff + scale_fill_manual( values = c("grey", "steelblue3")) +
  scale_color_manual( values = c("grey", "steelblue3"))+theme(legend.position="none")
p.comp.NEC.diff = p.comp.NEC.diff + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_blank(), panel.border = element_blank(), axis.line = element_line(colour = "grey80")) 

p.comp.NEC.diff = p.comp.NEC.diff + scale_y_continuous(name ="Differences posterior density") 
p.comp.NEC.diff = p.comp.NEC.diff + scale_x_continuous(name ="Standardized effect size")


#Rename & show plot
comp.plot.Tol.19Nov.surv.NEC.diff <- p.comp.NEC.diff
comp.plot.Tol.19Nov.surv.NEC.diff
```


##### If no difference was detected -> calculate NEC geometric mean and check against the original NECs

```{r}
NEC.Tol.19Nov.surv.geomean <- average_endpoints(x=list("Tol_PAR" = out.Tol.19Nov.surv.PAR.NEC, "Tol_UV" = out.Tol.19Nov.surv.UV.NEC), endpoint = "nec", xform = inv.log10)
NEC.Tol.19Nov.surv.geomean
NEC.Tol.19Nov.surv.PAR
NEC.Tol.19Nov.surv.UV
```

----------------------------------------------------------------
----------------------------------------------------------------


## Create layouts and export (if required)


Create layout to view result plots side-by-side
```{r}
layout.Tol.19Nov.surv <- ggarrange(plot.Tol.19Nov.surv.all, comp.plot.Tol.19Nov.surv.LC50, plot.Tol.19Nov.surv.NEC, comp.plot.Tol.19Nov.surv.NEC,
          ncol = 2, nrow = 2,
          widths = c(0.5, 0.5))
layout.Tol.19Nov.surv
```

